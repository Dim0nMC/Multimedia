{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e359ffc0",
   "metadata": {},
   "source": [
    "# Лабораторная работа №6\n",
    "\n",
    "Селивёрстов Д.С. М8О-401Б-21\n",
    "\n",
    "# Выбор датасета\n",
    "\n",
    "Выбранный датасет - \"CIFAR-10\".\n",
    "\n",
    "*Описание*:\n",
    "- 60,000 изображений размером 32x32 пикселя (3 канала).\n",
    "- 10 классов: `airplane`, `automobile`, `bird`, `cat`, `deer`, `dog`, `frog`, `horse`, `ship`, `truck`.\n",
    "- Разделён на 50,000 обучающих и 10,000 тестовых примеров.\n",
    "\n",
    "\n",
    "*Задача классификации*: классификация объекта на изображении в один из 10 классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f21e42",
   "metadata": {},
   "source": [
    "# Метрики\n",
    "\n",
    "- Accuracy (доля правильных предсказаний): подходит, т.к. классы сбалансированы (примерно по 6,000 изображений на класс), даёт быструю общую оценку качества модели.\n",
    "\n",
    "- F1-Score: показывает качество предсказаний по всем классам, особенно при анализе ошибок.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381ed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.13.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "Downloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e2af4f",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91318fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Используемое устройство:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a89c995",
   "metadata": {},
   "source": [
    "### Преобразования и загрузка CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc530419",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = trainset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa70c17",
   "metadata": {},
   "source": [
    "### Обучение сверточной модели (ResNet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d6ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "model_resnet = resnet18(pretrained=True)\n",
    "model_resnet.fc = nn.Linear(model_resnet.fc.in_features, 10)\n",
    "model_resnet = model_resnet.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_resnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c170938",
   "metadata": {},
   "source": [
    "Функция обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, criterion, optimizer, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(trainloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"\\nЭпоха {epoch + 1}, Потери: {running_loss / len(trainloader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f7a5a",
   "metadata": {},
   "source": [
    "Обучение ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231beac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [02:36<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 1, Потери: 0.2430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [02:37<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 2, Потери: 0.2417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [02:36<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 3, Потери: 0.2419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model_resnet, trainloader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a7718",
   "metadata": {},
   "source": [
    "### Обучение трансформера (deit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5851cd9",
   "metadata": {},
   "source": [
    "Обучение deit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09656b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.30.2)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a92e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa278c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('deit_tiny_patch16_224', pretrained=True, num_classes=10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f47021",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "def train_model(model, trainloader, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(trainloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"\\nЭпоха {epoch + 1}, Потери: {running_loss / len(trainloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc9994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [03:05<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 1, Потери: 0.3291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [03:05<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 2, Потери: 0.2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [03:05<00:00,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 3, Потери: 0.1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37537c",
   "metadata": {},
   "source": [
    "### Оценка по метрикам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_resnet(model, testloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    acc = MulticlassAccuracy(num_classes=10, average='macro')(all_preds, all_labels)\n",
    "    f1 = MulticlassF1Score(num_classes=10, average='macro')(all_preds, all_labels)\n",
    "    print(f\"Accuracy: {acc:.4f}, Macro F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate_model_deit(model, testloader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score (weighted): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab64da04",
   "metadata": {},
   "source": [
    "Оценка ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd24e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8763, Macro F1-score: 0.8766\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_resnet(model_resnet, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde8cde",
   "metadata": {},
   "source": [
    "Оценка ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab739ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9223\n",
      "F1 Score (weighted): 0.9218\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_deit(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6ffda2",
   "metadata": {},
   "source": [
    "### Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de2368",
   "metadata": {},
   "source": [
    "Добавим аугментации данных при обучении моделей.\n",
    "\n",
    "- RandomHorizontalFlip: поворачивает изображение по горизонтали, что помогает избежать переобучения.\n",
    "- RandomCrop: обрезка с последующим ресайзом усиливает устойчивость модели.\n",
    "- ColorJitter: случайно меняет яркость, контраст и насыщенность.\n",
    "- RandomRotation: немного поворачивает изображения, имитируя реальную вариацию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e94363",
   "metadata": {},
   "source": [
    "Обновим трансформации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67aed1e",
   "metadata": {},
   "source": [
    "Обучение Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0d837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [05:21<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 1, Потери: 0.4117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [05:20<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 2, Потери: 0.3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [05:18<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 3, Потери: 0.2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_resnet.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, trainloader, criterion, optimizer, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(trainloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"\\nЭпоха {epoch + 1}, Потери: {running_loss / len(trainloader):.4f}\")\n",
    "\n",
    "train_model(model_resnet, trainloader_aug, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d583b4b7",
   "metadata": {},
   "source": [
    "Обучение deit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3713a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [05:45<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 1, Потери: 0.2446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [05:46<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 2, Потери: 0.2089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [05:45<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 3, Потери: 0.1825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "train_model(model, trainloader_aug, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac48feff",
   "metadata": {},
   "source": [
    "Оценка ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82add886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8964, Macro F1-score: 0.8972\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_resnet(model_resnet, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bf86c1",
   "metadata": {},
   "source": [
    "Оценка ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6373770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9222\n",
      "F1 Score (weighted): 0.9224\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_deit(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378453fc",
   "metadata": {},
   "source": [
    "### Сравнение результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72125b40",
   "metadata": {},
   "source": [
    "| Модель     | Accuracy (до) | F1 (до)    | Accuracy (после) | F1 (после)  |\n",
    "|------------|---------------|------------|------------------|-------------|\n",
    "| ResNet18   | 0.8763        | 0.8766     | **0.8964**       | **0.8972**  |\n",
    "| DeiT-tiny  | 0.9223        | 0.9218     | **0.9222**       | **0.9224**  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733657eb",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc6728",
   "metadata": {},
   "source": [
    "Аугментации данных — простой и эффективный способ улучшить качество ResNet18.\n",
    "\n",
    "Они помогают предотвратить переобучение и обучить более устойчивую модель на относительно небольшом датасете, как CIFAR-10.\n",
    "\n",
    "DeiT уже показывает высокий уровень качества без аугментаций.\n",
    "\n",
    "Его архитектура и предобученность дают сильный старт. Аугментации дали лишь микроскопическое улучшение.\n",
    "\n",
    "Вывод:\n",
    "\n",
    "- Для простых моделей, таких как ResNet18, улучшения бейзлайна через аугментации — высокоэффективны.\n",
    "\n",
    "- Для более мощных моделей, таких как DeiT, дальнейшее улучшение стоит искать в более продвинутом тюнинге: подбор learning rate, scheduler, optimizer, увеличение числа эпох, возможно fine-tuning последних слоёв, если обучать на своих данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d70a9cc",
   "metadata": {},
   "source": [
    "## Имплементация алгоритма машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b442a3",
   "metadata": {},
   "source": [
    "Импорты и подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183cb51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa84dbc",
   "metadata": {},
   "source": [
    "Загрузка и подготовка CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fcc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac178d3",
   "metadata": {},
   "source": [
    "Свёрточная модель (простая CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96569bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 32x16x16\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 64x8x8\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "model_cnn = SimpleCNN().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06106dd",
   "metadata": {},
   "source": [
    "Обучающая функция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a315d",
   "metadata": {},
   "source": [
    "Функция оценки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d25a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    preds, labels_all = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            preds.extend(predicted.cpu().numpy())\n",
    "            labels_all.extend(labels.numpy())\n",
    "\n",
    "    acc = accuracy_score(labels_all, preds)\n",
    "    f1 = f1_score(labels_all, preds, average='macro')\n",
    "    print(f\"Accuracy: {acc:.4f}, Macro F1-score: {f1:.4f}\")\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7081302",
   "metadata": {},
   "source": [
    "Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e64d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels=3, patch_size=4, emb_size=128, img_size=32):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.emb_size = emb_size\n",
    "        self.n_patches = (img_size // patch_size) ** 2\n",
    "        self.proj = nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)  # (B, emb_size, H/patch, W/patch)\n",
    "        x = x.flatten(2)  # (B, emb_size, n_patches)\n",
    "        x = x.transpose(1, 2)  # (B, n_patches, emb_size)\n",
    "        return x\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, emb_size=128, num_heads=4, dropout=0.1, forward_expansion=4):\n",
    "        super().__init__()\n",
    "        self.layernorm1 = nn.LayerNorm(emb_size)\n",
    "        self.attn = nn.MultiheadAttention(emb_size, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.layernorm2 = nn.LayerNorm(emb_size)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_size, emb_size * forward_expansion),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(emb_size * forward_expansion, emb_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_attn = self.attn(x, x, x, need_weights=False)[0]\n",
    "        x = x + x_attn\n",
    "        x = self.layernorm1(x)\n",
    "\n",
    "        x_mlp = self.mlp(x)\n",
    "        x = x + x_mlp\n",
    "        x = self.layernorm2(x)\n",
    "        return x\n",
    "\n",
    "class SimpleViT(nn.Module):\n",
    "    def __init__(self, img_size=32, patch_size=4, in_channels=3, emb_size=128, num_classes=10, depth=6):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedding(in_channels, patch_size, emb_size, img_size)\n",
    "        n_patches = (img_size // patch_size) ** 2\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, emb_size))\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, n_patches + 1, emb_size))\n",
    "\n",
    "        self.transformer = nn.Sequential(*[\n",
    "            TransformerEncoder(emb_size) for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "        self.norm = nn.LayerNorm(emb_size)\n",
    "        self.head = nn.Linear(emb_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)  # (B, n_patches, emb_size)\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # (B, 1, emb_size)\n",
    "        x = torch.cat([cls_tokens, x], dim=1)  # (B, n_patches+1, emb_size)\n",
    "        x = x + self.pos_embed\n",
    "\n",
    "        x = self.transformer(x)\n",
    "        x = self.norm(x[:, 0])  # Use cls token\n",
    "        return self.head(x)\n",
    "\n",
    "model_vit = SimpleViT().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4f7cdc",
   "metadata": {},
   "source": [
    "### Обучение и оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dfbd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3590\n",
      "Epoch 2/10, Loss: 0.9792\n",
      "Epoch 3/10, Loss: 0.8207\n",
      "Epoch 4/10, Loss: 0.7047\n",
      "Epoch 5/10, Loss: 0.6053\n",
      "Epoch 6/10, Loss: 0.5161\n",
      "Epoch 7/10, Loss: 0.4225\n",
      "Epoch 8/10, Loss: 0.3461\n",
      "Epoch 9/10, Loss: 0.2717\n",
      "Epoch 10/10, Loss: 0.2131\n",
      "Accuracy: 0.7145, Macro F1-score: 0.7152\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_cnn = optim.Adam(model_cnn.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model_cnn, train_loader, optimizer_cnn, criterion, epochs=10)\n",
    "acc_cnn, f1_cnn = evaluate_model(model_cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d44ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.7826\n",
      "Epoch 2/10, Loss: 1.5027\n",
      "Epoch 3/10, Loss: 1.3796\n",
      "Epoch 4/10, Loss: 1.2858\n",
      "Epoch 5/10, Loss: 1.2208\n",
      "Epoch 6/10, Loss: 1.1552\n",
      "Epoch 7/10, Loss: 1.1012\n",
      "Epoch 8/10, Loss: 1.0544\n",
      "Epoch 9/10, Loss: 0.9977\n",
      "Epoch 10/10, Loss: 0.9524\n",
      "Accuracy: 0.6136, Macro F1-score: 0.6108\n"
     ]
    }
   ],
   "source": [
    "optimizer_vit = optim.Adam(model_vit.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model_vit, train_loader, optimizer_vit, criterion, epochs=10)\n",
    "acc_vit, f1_vit = evaluate_model(model_vit, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5619c7d",
   "metadata": {},
   "source": [
    "### Сравнение и выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2e8cff",
   "metadata": {},
   "source": [
    "| Модель                      | Accuracy | F1-score (macro/weighted) |\n",
    "|----------------------------|----------|----------------------------|\n",
    "| **ResNet18 (базовый)**     | 0.8763   | 0.8766                     |\n",
    "| **DeiT Tiny (базовый)**    | 0.9223   | 0.9218                     |\n",
    "| **Собственная CNN**        | 0.7145   | 0.7152                     |\n",
    "| **Собственный ViT**        | 0.6136   | 0.6108                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cea8776",
   "metadata": {},
   "source": [
    "- DeiT Tiny остаётся самой точной моделью.\n",
    "\n",
    "- Собственные реализации ViT и CNN работают хуже предобученных моделей. Это ожидаемо:\n",
    "\n",
    "  1. Упрощённый ViT страдает из-за меньшей глубины и отсутствия предобученных весов.\n",
    "\n",
    "  2. Простая CNN не может конкурировать с глубокими архитектурами без серьёзной доработки.\n",
    "\n",
    "- Эти результаты подчёркивают важность предварительного обучения и архитектурной глубины для современных моделей — особенно для трансформеров, которым требуется много данных и вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a777097",
   "metadata": {},
   "source": [
    "### Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Аугментации для обучения\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Аугментации для валидации/тестов\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                         download=True, transform=train_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=test_transform)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29953aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 56 * 56, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=128):\n",
    "        super().__init__()\n",
    "        self.patch_dim = patch_size * patch_size * in_channels\n",
    "        self.n_patches = (img_size // patch_size) ** 2\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)  # (B, embed_dim, H, W)\n",
    "        x = x.flatten(2)  # (B, embed_dim, N)\n",
    "        x = x.transpose(1, 2)  # (B, N, embed_dim)\n",
    "        return x\n",
    "\n",
    "class SimpleViT(nn.Module):\n",
    "    def __init__(self, num_classes=10, embed_dim=128, num_heads=4, depth=4):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedding(embed_dim=embed_dim)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, 197, embed_dim))  # 196 patches + 1 cls\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        cls_tokens = self.cls_token.expand(x.size(0), -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.pos_embed[:, :x.size(1), :]\n",
    "        x = self.transformer(x)\n",
    "        return self.mlp_head(x[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0afd18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.numpy())\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    print(f\"Accuracy: {acc:.4f}, Macro F1-score: {f1:.4f}\")\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c9f7d7",
   "metadata": {},
   "source": [
    "Обучение и метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17631cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.9169\n",
      "Epoch 2, Loss: 1.6127\n",
      "Epoch 3, Loss: 1.4981\n",
      "Epoch 4, Loss: 1.4473\n",
      "Epoch 5, Loss: 1.3839\n",
      "Accuracy: 0.5538, Macro F1-score: 0.5501\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "cnn = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=1e-3)\n",
    "train_model(cnn, train_loader, criterion, optimizer, epochs=5)\n",
    "acc_cnn, f1_cnn = evaluate_model(cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce6da25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3253\n",
      "Epoch 2, Loss: 2.3087\n",
      "Epoch 3, Loss: 2.3060\n",
      "Epoch 4, Loss: 2.3051\n",
      "Epoch 5, Loss: 2.3043\n",
      "Accuracy: 0.1000, Macro F1-score: 0.0182\n"
     ]
    }
   ],
   "source": [
    "# Vision Transformer\n",
    "vit = SimpleViT().to(device)\n",
    "optimizer = optim.Adam(vit.parameters(), lr=1e-3)\n",
    "train_model(vit, train_loader, criterion, optimizer, epochs=5)\n",
    "acc_vit, f1_vit = evaluate_model(vit, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b725e03",
   "metadata": {},
   "source": [
    "### Сравнение и выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba43adae",
   "metadata": {},
   "source": [
    "| Модель                   | Accuracy | Macro F1-score |\n",
    "|--------------------------|----------|----------------|\n",
    "| ResNet (pretrained)      | 0.8964   | 0.8972         |\n",
    "| DeiT Tiny (pretrained)   | 0.9222   | 0.9224         |\n",
    "| Simple CNN (custom)      | 0.5538   | 0.5501         |\n",
    "| Simple ViT (custom)      | 0.1000   | 0.0182         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd03a6e2",
   "metadata": {},
   "source": [
    "1. Предобученные модели (ResNet и DeiT) с улучшенным бейзлайном (аугментации RandAugment) показали высокие результаты, особенно DeiT (Accuracy > 92%).\n",
    "\n",
    "2. Собственные реализации моделей, несмотря на применение таких же аугментаций, значительно уступают по качеству:\n",
    "\n",
    "  - Simple CNN достигла лишь ~55% Accuracy.\n",
    "\n",
    "  - Simple ViT почти не обучился, его Accuracy ≈ случайному угадыванию.\n",
    "\n",
    "3. Это объясняется:\n",
    "\n",
    "  - Отсутствием глубоких архитектур и обилия параметров в самописных моделях.\n",
    "\n",
    "  - Недостаточной тренировкой (мелкие трансформеры сложны для обучения \"с нуля\").\n",
    "\n",
    "  - Отсутствием оптимизаций, применённых в продвинутых моделях (timm, torchvision).\n",
    "\n",
    "4. Улучшенный бейзлайн критически важен для достижения высоких метрик, но предобученные веса и зрелые архитектуры — основа хорошей производительности."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
